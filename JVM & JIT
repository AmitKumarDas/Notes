 
 Whats a JIT
 --------------
 - just-in-time (JIT) compiler is a program that turns Java bytecode
 - - (a program that contains instructions that must be interpreted) 
 - - into instructions that can be sent directly to the processor.
 - Using the Java just-in-time compiler at the particular system platform compiles the bytecode into 
 - - the particular system code (as though the program had been compiled initially on that platform).
 - - Once the code has been (re-)compiled by the JIT compiler, it will usually run more quickly in the computer. 
 - Sun Microsystems suggests that it's usually faster to select the JIT compiler option, 
 - - especially if the method executable is repeatedly reused.
 
 Running JIT
 ---------------------
 - JIT compiler achieves most of its speed improvements the second time it calls a method. 
 - The JIT compiler does compile the whole method INSTEAD of interpreting it line by line 
 - - which can also be a performance gain for when running an application with the JIT enabled.
 
 
 View JIT compiled code
 --------------------------
 - check the JVM options
 - first need to do a probably,
 - - XX:+UnlockDiagnosticVMOptions
 - - XX:+PrintAssembly
 - need to have some debug binaries too
 
 JIT & Lock Coarsening
 -----------------------
 public void needsLocks(){
  for(option:options){
   process(option);   //repeated locking
  }
 }
 
 private synchronized String process(String option){
   //some thread unsafe code
 }
 
 //JITed
 
 public void needsLocks(){
  synchronized(this){ //lock ONCE
   for(option:options){
     process(option);
   }
  }
 }
 
 JIT & Lock Eliding
 -----------------------
 public void overCautious(){
  List l = new ArrayList();
  synchronized(l){
   for (option:options){
     l.add(process(option);
   }
  } 
 }
 
 //JITed
 public void overCautious(){
  List l = new ArrayList(); // no need to lock 
   for (option:options){
     l.add(process(option);  
  } 
 }
 
 
 - JIT & Code Ordering
---------------------------
 - Compilers have a lot of freedom to reorder code in the absence of synchronization; 
 - they could either reorder the writes in threadOne or the reads in threadTwo freely. 


 Large Methods & Code Inlining
---------------------------------
 - JIT won't inline if the method gets too large. 
 - Introducing sampling into the methods changes the size, and therefore affects inlining decisions, 
 - - changing the performance characteristics of your code.

 Location of SafePoints
---------------------------
 - Safe points are places in the code that the VM knows it can do a whole host of things -
 - - like initiate garbage collection - safely. 
 - The location of these safe points is determined by the JIT. 
 - system-wide stack trace sampling happens for any given thread when it is at a safe point. 


 - Be Careful about
-----------------------
 1/ Atomicity
 2/ Visibility
 3/ Ordering

 JIT Compilation
--------------------
  > transforms code
  > code actually executed can be different than the code you write

  Compiler Tricks - Reads can be cached
----------------------------------------
  int distanceRatio(Object a) {
    int distanceTo = a.getX() - start;
    int distanceAfter = end - a.getX();
    return distanceTo/distanceAfter;
}

  Is same as 

  int distanceRatio(Object a) {
    int x = a.getX(); 
    int distanceTo = x - start; 
    int distanceAfter = end - x;
    return distanceTo/distanceAfter;
}

   - Compiler Tricks - Reads can be cached
----------------------------------------
  void loopUntilFlagSet(Object a) {
    while (!a.ﬂagIsSet()) {
    loopcount++;
  }
}

  Is same as:

  void loopUntilFlagSet(Object a) {
    boolean ﬂagIsSet = a.ﬂagIsSet();
    while (!ﬂagIsSet) {
      loopcount++;
  }
}


  Compiler Tricks 
-----------------------------------------------
  - Writes can be eliminated
  - Inlining

  public class Thing {
    private int x;
    public ﬁnal int getX() { return x };
  }
  ...
  myX = thing.getX();

  Is same as 

  Class Thing {
    int x;
  }
  ...
  myX = thing.x;


  JIT can do CHA
------------------
  > Class Hierarchy Analysis
  
  Adapting to Adaptive JIT
------------------------------
  > Trading system wants to have the first trade be fast
  > so run 20,000 fake messages thru the system to warm up
  > just make it real enough with proper source & sink

  
- JVM/JIT & Memory Fence Instructions
----------------------------------------
 - If the compiler generated bytecode that obeys the Java memory model, 
 - then the JVM/JIT will issue memory fence instructions when necessary - 
 - when reading/writing volatile variables, acquiring or releasing the monitors on objects etc.

  
 Memory Barriers/Fencing
---------------------------
 - set of processor instructions
 - to apply ordering limitations on memory ops
 
 Memory Barriers & Determinism of multi-threaded programs
------------------------------------------------------------
 - A main memory operation costs hundreds of clock cycles on commodity hardware. 
 - Processors use caching to decrease the costs of memory latency by orders of magnitude. 
 - These caches re-order pending memory operations for the sake of performance. 
 - In other words, the reads and writes of a program are not necessarily performed in the order 
 - - in which they are given to the processor. 
 - When data is immutable and/or confined to the scope of one thread these optimizations are harmless.

 - Memory Barriers & JVM
--------------------------
 - MBs r not exposed by JVM
 - JVM injects instructions to enable fencing





References
---------------
1/ http://www.infoq.com/presentations/JVM-Mechanics


