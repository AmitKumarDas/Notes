 -0 Suggested Solutions
------------------------
  > http://www.warski.org/blog/2012/06/implementing-message-replication-in-elasticmq-with-jgroups/
  > http://www.rabbitmq.com/blog/2010/09/22/broker-vs-brokerless/
  > http://puniverse.github.com/galaxy/about.html
  > start archiving inactive users's session  
  >> will be done automicatlly if we have a LRU on an IMDB & persist that on disk
  > https://github.com/jbrisbin/vcloud/tree/master/session-manager
  >> provide session failover & cluster wide load balancing without relying on sticky sessions
  > 


 -0 Points to Remember
---------------------------
    - Value Add
    - Who will buy
    - Install and migration
    - Extra support activity
    - Risks
    - Effort
    - Stability
    - Technological Acceptance 

  
 -0 A real time Game App
  > Batch the 'Intense but short lived sessions'
   1/ to avoid HTTP overhead, batch the actions
   >> 1 HTTP request = 6 actions
  > Scale Out
   1/ Distributing sessions across multiple servers   
   >> simple algo = session_id % 2 -> 0 or 1 -> i.e. channel to 2 different nodes
   >> this algorithm can be provided to load balancers routing logic
   >> assumptions - session_id is incremented by 1 
   >> during failover this rule should be avoided
  > Concurrent Programming
   1/ Threads
   >> Tomcat :: 1 acceptor thread, 30 worker threads
   >> Application :: 1 ticker thread - shuts down inactive sessions
   >> Application :: 1 broadcast thread - tells other shards about updates
 




 -0 Clustering Connection
------------------------------
  > client shuld not hard code the node host names or IP addresses
  > should be dynamic DNS service
  > or plain TCP load balancer


 -0 RabbitMQ Clustered = Mirroring
-------------------------
  > Mirroring done on Qs
  > one master & several slaves .. each on different node
  > all actions other than publishing go only to the master
  > master then broadcasts the effect of the actions to the slaves
  > when a new node is added as a slave... this new slave will add new ops on master
  > Mirroring can be configured to apply on specific nodes of a cluster
  > On loss of the Master
  >> any messages that the master was in the process of sending to the slaves either fail completely 
  >> or succeed completely (this is really the atomic in atomic broadcast).
  > all communication between the members of the mirror occurs in an async fashion


 -0 RabbitMQ Clustering does only the below
----------------------------------------------
  > All data/state required for the operation of a RabbitMQ broker is replicated across all nodes, 
  > for reliability and scaling, with full ACID properties. 
  > An exception to this are message queues, which by default reside on the node that created them, 
  > though they are visible and reachable from all nodes. 
  

 -0 RabbitMQ Load balancing
--------------------------
  > RabbitMQ cluster doesnot mean load balancing
  > need to frontend with HAProxy
  > Here HAProxy will balance the request only on ONE node, i.e. Server Affinity
  >> If this node fails the request will be route to the other node. Itâ€™s simple as that.
  > The use of HAProxy makes sense if you have implemented the mirrored queue


 -0 RabbitMQ Failover
---------------------------
  > RabbitMQ cluster intention is to facilitate scalability
  > not for availability
  > i.e. not for HA(High Availability) clusters
  > For high availability you need :: Active / Passive Cluster :: with below as common platform
  >> 1/ DRBD - Distributed Replicated Block Device - GNU/Linux platform
  >> 2/ Pacemaker - cluster resource manager for Linux platform - GPLv2
  >> 3/ OpenAIS or CoroSync or Heartbeat


 -0 HAProxy
--------------------
  > TCP/HTTP Load Balancer
  > implements an event-driven, single-process - for concurrent connections @ high speeds
  > 


 -0 State Management
-------------------------
  > most languages & runtimes donot have a safe solution for concurrent long lived session
  > Erlang stands out


 -0 ZooKeeper
----------------------
  > highly available, scalable, distributed configuration, consensus, group membership, leader election
  > a system for coordinating distributed processes
  > In order to be useful Zookeeper must be highly reliable & available as systems will depend on former .. 


 -0 Zookeeper Recipes
-------------------------
  > Use Zk to implement below:
  >> barriers
  >> locks
  >> queues
  >> counter
  >> 2 phase commit
  >> leader election

 -0 Zookeeper - a low level stuff
--------------------------------------
  > is a low level stuff
  > need some libraries i.e. wrapper on top of Zk to prove Zk
  > Netflix's Curator is one such

 -0 Zookeeper - Recipe - Distributed bag
-----------------------------------------
  > allows processes to share a collection
  > Any participant can post or remove data alerting all others
  > useful for cases where processes need to share configuration determined @ runtime
  > used as a part of Role Match
  > provides event based subscriptions making implementation simpler
  > 





 -0 Zookeeper Service
------------------------
  > all servers store a copy of the data in memory
  > leader is elected @ startup
  > all updates go through the leader
  > responses are sent when a majority of servers have persisted the change

 -0 ZeroMQ
--------------------
  > push pull
  > req-rep
  > pub-sub (multicast, broadcast)
  > workload distribution

 -0 Kafka/Redis
-----------------
  > push-pull with persistence
  > workload buffering & distribution





 -0 Typical Session State size
-------------------------------
  > 3 to 200 KB
  > 


 -0 high availability
----------------------
  > requires a stateful-failover architecture

 -0 Cost of Replicating Sessions
------------------------------------
  > if each session is mirrored across entire pool of app servers
  > each server must use memory to store that session
  > each mirrored session is going to consume resources on their respective app server
  > however, app server has a limited amount of memory
  > aliter - memory is required for various other purposes too
  > this will reduce the memory for other important tasks
  > hence, speed required to execute app logic will reduce
  > Hence, more scalability, i.e. highly failover requirement, will push for more servers
  > with each server addition, session memory consumption per server increases & 
  > in turn more slower performance
  > In short period of time, system wont be scalable further

 -0 High Available Solution
---------------------------------
  > shared database in application along with load balancers
  > server affinity i.e. sticky session based load balancers
   >> however, above requires an assumption on session
   >> can be any data in the HTTP headers
   >> or any data in HTTP payload
   >> but using the automatically generated session ids tend to be the most common implementation 


-0 Performance Aspects
---------------------------
  > should perform in large distributed systems
  > 

 -0 Reliability Aspects
---------------------------
  > avoid single point of failure
  > 

 -0 Synchronization Aspects
------------------------------
  > support synchronous as well as sync
  > support events
  > support heartbeats
  > 


 -0 Monitoring Aspects
-------------------------
  > if Read request registers a watch that watch is tracked locally @ the server
  > 

 -0 In-Memory data
---------------------------
  > achive high throughput & low latency
  > by avoiding disk I/O
  > downside - size of database is limited by memory

 -0 Clustered In-memory data
-----------------------------
  > in a clustered environ, the db could be partitioned
  > then replicated into segments
  > & stored in main memory of several nodes
  > 

 -0 Centralized Server
--------------------------
  > clients connect to a Single server
  > if client to server connection breaks, client will connect to a different server
  > session will get restablished in the new server

 -0 Request Types
---------------------------------------
  > support multiple request types
  > Read, Write, Sync
  > Read requests are processed locally to which the client is connected
  > Write requests are forwarded to other servers & go through a consensus before a response is generated
  > Sync requests are forwarded to other servers but do not go through consesus
  > throughput of read requests scales with no of servers
  > throughput of write requests decrease with no of servers
  > All updates are ordered

 -0 Centralized Metadata Management
----------------------------------------
  > store coordinate data
  > store status info
  > location info

 -0 Replication
----------------------
  > replicate on create
  > replicate on faliure




References
----------------
1/ https://devcentral.f5.com/blogs/us/sessions-sessions-everywhere
2/ http://blog.cloudera.com/blog/2009/05/building-a-distributed-concurrent-queue-with-apache-zookeeper/
3/ http://www.slideshare.net/wooga/how-to-handle-1000000-daily-users-without-using-a-cache-railswaycon-2012
4/ http://www.slideshare.net/wooga/statefulapplicationserverrupy-2012brno
