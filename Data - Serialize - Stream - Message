


 Access this C structure via TypedArray
-----------------------------------------
struct someStruct {
  unsigned long id;
  char username[16];
  float amountDue;
};
You can access a buffer containing data in this format like this:

var buffer = new ArrayBuffer(24);
// ... read the data into the buffer ...
var idView = new Uint32Array(buffer, 0, 1);
var usernameView = new Uint8Array(buffer, 4, 16);
var amountDueView = new Float32Array(buffer, 20, 1);


unicode-encoded String
---------------------------
  > i.e. treating RAW data as String
  > --> use charCodeAt() to read bytes from the data buffer

 charCodeAt(index)
------------------
  > returns Numeric Unicode value of the character at the given index 


Binary Data Vs. unicode-encoded Strings
-------------------------------------------
  > not the same
  > may be ok in browser w.r.t unicode-encoded String
  > In Browser most data is in form of String
  > Consider server side cases
  > --> server has to handle TCP streams
  > --> server has to read / write to files
  > --> SO its necessary to deal with PURELY binary form of data

 NodeJS --> Binary Strings Vs Buffers
----------------------------------------
  > Each Buffer  =  some raw memory allocated outside V8
  > Buffer ~ similar to ~ Array of Integers
  > The Integer in the Buffer ~ represent ~ a Byte
  > SO Integer range ~ 0 to 255 (inclusive)
  > --> NOTE - Contents of this ARRAY r integers representing BYTES

 NodeJS --> Buffer --> Use
------------------------------
  > Initialize like an array
  > write stuff in string
  > NOTE - give the encoding type
  > Encoding Type --> ascii, utf-8, ucs2, base64
  > We can specify an OFFSET too i.e. INDEX of the buffer to start writing to

 NODEJS --> Buffer --> toString
--------------------------------
  > Provides the actual string data we fed to the buffer
  > If the Buffer was not filled completely, you will find bytes as o/p along with your string that was fed

 NODEJS --> Buffer --> Individual Octects
------------------------------------------
  > Setting individual bits .. possible
  > its easy - think like arrays

 NODEJS --> Buffer --> More Stuff
-------------------------------------------
  > isBuffer & byteLength
  > byteLength is different than length
  > --> no of bytes vs. no of integers in Array
  > buffer.copy & buffer.slice

 TypedArray Specs --> Buffer & View
------------------------------
  > Buffer via ArrayBuffer --> represents chunk of data
  > Buffer --> no format, no mechanism to access its contents
  > View --> provides context --> data type, offset, no of elements
  > View --> via ArrayBufferView class
 


 COmbining single buffer with multiple views
-------------------------------------------------
  > --> can interact with data objects containing multiple data types
  > interact with WebGL, data files or C structures

Character - Hows & Whys
-----------------
  > characters r represented in UNICODE by Numbers called code points/ scalar values
  > These nunbers can range from 0 up to 1,114,111
  > each code point can be directly encoded with a 32 bit code unit


 UTF-8 ... WHY ?
-------------------
  > need for a GOOD BYTE STREAM ENCODING OF MULTI-BYTE CHARACTER SETs  
  > backward compatibility with ASCII
  > avoid endianess & byte order marks in UTF-16 & UTF-32
  > efficient to encode using bit operations.
  > no need of slow math ops like multiply or divide
  > character boundaries are easily found when searching forwards or backwards
  > if bytes are lost due to corruption or error, 
  > -> one can locate the beginning of next character thus limiting the damage
  > can be used for byte oriented string search algo  


 UTF-8 -> Hows ?
------------------------
  > Get the character
  > Get the Unicode code point for the character
  > Convert to binary code point
  > This will tell you the byte size
  > Depending on byte size, append leading 1 'size' no of times to first byte, then append leading 0
  > append 10 to other bytes
  > Above is Binary UTF-8
  > Converting to Hexadecimal UTF-8 etc is usual stuff

 UTF-8 -> Popularity
----------------------
  > default character ENCODING IN
  > OS, programming languages, APIs & s/w apps

 UTF-8 & ASCII
-------------------
  > first 128 characters of UNICODE corrspond one-to-one with ASCII
  > > are encoded using single octet with same binary value as ASCII
  > > hence, a valid ASCII text is a valid UTF-8 encoded Unicode as well

 UTF-8 -> Security
------------------------
  > invalid UTF-8 has been used to bypass security validations in IIS & Tomcat 
  > Have stricter decoders

 C Structs
---------------
  > includes pad bytes to maintain alignment for C types involved
  > C Types represented in machine's native format & byte order
  
  C Type -> Byte Order
-------------
  > can be native / little-endian / big-endian / network (=big-endian)
  > depends on host system


  C Type  -> Size
--------------
  > can be native or standard

  C Type -> Alignment
------------------
  > can be native / none


  JSON Stringify
------------------
  > When you prepare for a transmit the data is JSON Stringified

  JSON Parse
-----------------
  > When you accept a transmitted data you parse the data

   Receive Data + NODE JS Snippet
--------------------------------
  > JSON.parse the data
  > if data is base64 encoded then decode 
  > raw = new Buffer(base64decoded, 'binary')
  > socket.write(raw)
 

 Python Struct
--------------
  > provides conversion between Python values & C structs
  > C structs represented as Python strings

  When is handling binary data required ?
-------------------------------------------
  > can be stored in files
  > can be transferred in network
  > Python struct module can be used to handle binary data




 
 Java - Custom ObjectInputStream - If AtAll
-----------------------------------
  > very basic steps to handle Java primitive type  
  > check for primitive types & return its Class
  > else get the classloader & get the Class

 Java -- DataOutputStream & ObjectOutputStream
-------------------------------------------
  > DataInput/Output - simpler - read/write primitive types & Strings
  > ObjectInput/Output - less efficient - read/write complex data

 Java -- ObjectOutputStream
----------------------
  > write Java objects to OutputStream
  > so not just bytes... but Java Bytes
  > Java object need to implement Serializable

 -0 XMLStreamWriter -
-----------------------
  > enable writing of XML programmatically
  > check if proper escaping is enabled/disabled
  > i.e. < > etc special chars should be in place inside the XML

 -0 Write events to DISK
----------------------------
  > use XMLStreamWriter
  > use FileWriter to open up a file on disk

 -0 Write XML to System.out
-----------------------------
  > use XMLStreamWriter
  > use System.out

 -0 Convert XML from library A's type into library B's type
-------------------------------------------------
  > serialize library A's object into outputstream via XMLStreamWriter
  > feed a inputstream from above output stream
  > create library B's object from inputstream via some parser library

 -0 org.w3c.dom.Document + Generate
------------------------------------
  > use javax.xml.parsers.DocumentBuilder
  > parse the inputstream using DocumentBuilder


 -0 Serialize java object to OutputStream
--------------------------------------------
  > serialize to ByteArrayOutputStream
  > serialize may be implemented by the java object
  > e.g. serialize using XMLStreamWriter
  > > more formatting via decorators etc
  
 -0 Write a XML Document to XXX
------------------------------
  > write a org.w3c.dom.Document to String/file/writer/stream
  > write to stream via StreamResult & java.io.ByteArrayOutputStream & ToXMLStream & DOMSource
  > write to file via StreamResult & java.io.FileWriter & ToXMLStream & DOMSource
  > write to Writer via StreamResult & java.io.Writer & ToXMLStream & DOMSource
  > StreamResult = javax.xml.transform.stream.StreamResult
  > ToXMLStream  = org.apache.xml.serializer.ToXMLStream
  > DOMSource    = javax.xml.transform.dom.DOMSource

 -0 Limitations of TCP
-------------------------
  > strict order of transmission delivery of data
  > head-of-line blocking offered by TCP causes unnecessary delay
  > Applications must add their own record marking to delineate their messages, 
  >> and must make explicit use of the push facility to ensure that a complete message is transferred.
  > The limited scope of TCP sockets complicates the task of providing highly-available data transfer 
  >> capability using multi-homed hosts.
  > TCP is relatively vulnerable to denial-of-service attacks, such as SYN attacks.

  -0 Features with SCTP
--------------------------
  > multi-homing support on both ends
  >> multi-homing = consist of more than one IP address
  >> enabling transparent failover between redundant network paths
  > multi stream - delivery of chunks with independent streams
  > validation & acknowledgement mechanisms protect against flooding attacks
  > provide notification of duplicated or missing data chunks
  > simpler packet structure than TCP
  > Security - 4 way handshake to protect against SYN flooding
  >> protect against large cookies for association verification & authenticity
  > Not supported directly in Windows







